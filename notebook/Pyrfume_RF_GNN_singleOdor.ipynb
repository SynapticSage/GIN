{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77518f85",
   "metadata": {
    "id": "LGz0DB7-1f0c"
   },
   "source": [
    "Name: Ryan Young\n",
    "\n",
    "Date: 2024-05-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5b38a",
   "metadata": {
    "id": "yejrQ-g50vYF"
   },
   "source": [
    "# Molecular Scent Analysis\n",
    "Hi!\n",
    "\n",
    "Welcome to this exploratory analysis notebook where we aim to predict whether a molecule might smell like a flower\n",
    "\n",
    "This notebook's goal is to demonstrate an approach to solving a problem related to molecular scent prediction, with a focus on exploratory data analysis, model evaluation, and visualization of results.\n",
    "\n",
    "Towards the end, we will also explore some problems related to message passing and graph neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec00d0",
   "metadata": {
    "id": "dtaFLFKizYVN",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Dependencies\n",
    "The following cell clones a private GitHub repo called `gin`\n",
    " -- where I developed the code for this analysis.\n",
    "\n",
    "Even with notebooks, I tend to modularize pieces into repos for\n",
    "- reproducibility\n",
    "- CI/CD\n",
    "- testing\n",
    "\n",
    "The \"fine-grained\" `access_token` token below grants permission to pull the private repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4ad8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "030e98c5-f7f4-4811-98a0-fc97b9cc0ce3",
    "lines_to_next_cell": 2,
    "outputId": "c5032aab-8eeb-422a-e2cf-f23660c85260"
   },
   "outputs": [],
   "source": [
    "#  # Imports and Argparse\n",
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gin\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import ensemble as sklearn_ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Predict the presence of a specific odor descriptor.')\n",
    "parser.add_argument('--archive', \n",
    "                    type=str, \n",
    "                    default='leffingwell',\n",
    "                    help='Name of the Pyrfume data archive to use.')\n",
    "parser.add_argument('--descriptor', \n",
    "                    type=str, \n",
    "                    default='floral',\n",
    "                    help='The odor descriptor to predict.')\n",
    "args = parser.parse_args()\n",
    "desc = args.descriptor\n",
    "args.script = \"Pyrfume_RF_GNN_singleOdor.py\"\n",
    "\n",
    "print(\" ------  ARGS -------- \")\n",
    "print(args)\n",
    "print(\" --------------------- \")\n",
    "\n",
    "# import seaborn as sns\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "# Save the figure\n",
    "figure_dir = os.path.join(os.path.dirname(gin.__file__), '..', 'figures', args.descriptor)\n",
    "print(\"Figure directory:\", figure_dir)\n",
    "os.makedirs(figure_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "figure_path = (lambda x=\"\": \n",
    "                os.path.join(figure_dir, f'{plt.gcf().get_suptitle() if not\n",
    "                                 x else x}.png'))\n",
    "df_path = os.path.join(figure_dir, \"..\", \"df.csv\") # WARNING: in the face of more analyses, may have to split this dataframe\n",
    "save_fig = lambda x=\"\": plt.savefig(figure_path(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f75c9",
   "metadata": {
    "title": "# SETUP"
   },
   "source": [
    "# MLFLOW\n",
    "This section sets up experiment tracking\n",
    "\n",
    "from gin.log.mlflow import start_run, log_params, log_metrics, log_artifacts, end_run\n",
    "\n",
    "start_run(run_name=\"Pyrfume_RF_GNN_singleOdor\")\n",
    "\n",
    "Log model parameters and metrics\n",
    "log_params(args.__dict__)\n",
    "log_metrics({\"metric1\": score1, \"metric2\": score2}) # example of how would log this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce958649",
   "metadata": {},
   "source": [
    "## Clear\n",
    "\n",
    "Check if the `gin` package is installed\n",
    "module_spec = importlib.util.find_spec('gin')\n",
    "module_spec\n",
    "\n",
    "Check if the `gin` package is installed, if refresh is True, then we will refresh the package\n",
    "refresh = False\n",
    "if module_spec and refresh:\n",
    "    shutil.rmtree(folder)\n",
    "    gin_path = os.path.dirname(module_spec.origin)\n",
    "    # NOTE: This is an access token fenced-off for this specific private repository - only usable to clone this single private repo.\n",
    "    repo_url = f'https://github.com/synapticsage/gin.git'\n",
    "    os.system(f'git clone {repo_url}')\n",
    "    os.chdir('gin')\n",
    "    # !pip install . \n",
    "    # pip install the package\n",
    "    # os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebab830",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.path.dirname(module_spec.origin)))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdd03e4",
   "metadata": {
    "id": "d538e6fc"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "Here we will use data managed by [the Pyrfume project](https://pyrfume.org/) \n",
    "\n",
    "The \n",
    "[SMILES strings](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) \n",
    "representing the molecular structures and their corresponding binary labels are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8827c5",
   "metadata": {
    "id": "264e66a1"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_df = gin.data.pyrfume.get_join(args.archive, \n",
    "                                    types=[\"behavior\", \"molecules\", \"stimuli\"])\n",
    "data_df = pd.DataFrame(data_df.set_index('SMILES')[desc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec312a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "314b5dc3-e331-4555-8184-739d0b2f684f",
    "outputId": "d64681f6-2985-40f1-f2b0-5902d747b84f"
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e0bed",
   "metadata": {
    "id": "af266b7c"
   },
   "source": [
    "\n",
    "Now that we have the data loaded, what should we learn about this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c4ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e91f4ee",
    "outputId": "676dd13a-287f-4809-8f5e-4e624d7baa34"
   },
   "outputs": [],
   "source": [
    "data_df[desc].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894618e9",
   "metadata": {
    "id": "2fd33ec1"
   },
   "source": [
    "\n",
    "No missing values - reassuring!\n",
    "\n",
    "Let's see the distribution of the labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06842a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "714f0c21",
    "outputId": "93543d52-12f6-4dfb-a811-ee1232cb13a1"
   },
   "outputs": [],
   "source": [
    "gin.explore.pyrfume.plot_desc_distribution(data_df, kind='pie', descriptor=desc)\n",
    "save_fig(f'{desc}_distribution')\n",
    "log_artifacts({\"class_distribution\": data_df[desc].value_counts().to_dict()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3499e0",
   "metadata": {
    "id": "d9d9222f"
   },
   "source": [
    "ðŸ‘† The large majority of the dataset is non-floral âŒðŸ’. We should consider **class imbalance** downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db046034",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "937701be",
    "outputId": "f85045b4-86c4-4187-89cf-ebbfa0a6d148"
   },
   "outputs": [],
   "source": [
    "# Let's visualize some of the molecular structures in the dataset and see if we can spot any patterns.\n",
    "gin.explore.pyrfume.plot_molecular_structures_w_label(data_df, num_samples=20, descriptor=desc)\n",
    "save_fig(f'{desc}_molecular_structures_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87f09e",
   "metadata": {
    "id": "2059e7bf"
   },
   "source": [
    "And let's examine a few more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661fde0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "1caefc10",
    "lines_to_next_cell": 1,
    "outputId": "cb27d07c-46e1-45c9-c6b4-73a9c855bf77"
   },
   "outputs": [],
   "source": [
    "gin.explore.pyrfume.plot_molecular_structures_w_label(data_df, num_samples=20, descriptor=desc)\n",
    "save_fig(f'{desc}_molecular_structures_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2b824",
   "metadata": {
    "id": "3b8a8363"
   },
   "source": [
    "## Hypotheses\n",
    "\n",
    "Some things of note just from the visualization (hypotheses / possibillium / wild guesses):\n",
    "\n",
    "- The ðŸª» floral molecules nearly all have oxygen with free electron pair. Doubled-bond oxygen alone  seems less often associated with floral molecules.\n",
    "- Nitrogen-containing rarely floral - though, devil's advocate, I also see fewer nitrogen-containing molecules to form an opinion.\n",
    "\n",
    "# Molecule Featurization\n",
    "\n",
    "In the next step, we will try to \"digitize\" each molecule by creating a 1D numpy array based on its molecular structure. Can you create a molecular fingerprint with `rdkit` ([documentation](https://www.rdkit.org/docs/GettingStartedInPython.html#fingerprinting-and-molecular-similarity))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a37076",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8133b2dc",
    "outputId": "7e3f1d34-986d-4a62-877d-2211f6cdd959"
   },
   "outputs": [],
   "source": [
    "def featurize_smiles(smiles_str: str,\n",
    "                     method: str = 'combined') -> np.ndarray:\n",
    "  \"\"\"Convert a molecule SMILES into a 1D feature vector.\"\"\"\n",
    "  if method == 'morgan':\n",
    "    fingerprint = gin.features.get_morgan_fingerprint(smiles_str)\n",
    "  elif method == 'maccs':\n",
    "    fingerprint = gin.features.get_maccs_keys_fingerprint(smiles_str)\n",
    "  elif method == 'combined':\n",
    "    fingerprint = gin.features.get_combined_fingerprint(smiles_str)\n",
    "  else:\n",
    "    raise ValueError(f\"Invalid method: {method}\")\n",
    "  return fingerprint\n",
    "\n",
    "# Test the function\n",
    "featurize_smiles('CC(C)CC(C)(O)C1CCCS1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c554fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "6c58eeaa",
    "outputId": "8fb58cc9-43f7-4c79-efab-250dcb1f04b6"
   },
   "outputs": [],
   "source": [
    "# Construct the features `x` and labels `y` for the model\n",
    "x = np.array([featurize_smiles(v) for v in data_df.index])\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "label_encoder = OrdinalEncoder()\n",
    "x = label_encoder.fit_transform(x)\n",
    "y = data_df['floral'].values\n",
    "gin.explore.pyrfume.plot_feature_heatmap(x)\n",
    "save_fig(f'{desc}_feature_heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae99c24",
   "metadata": {
    "id": "604a9a65"
   },
   "source": [
    "Having noticed the above, we should maybe be thinking about the following\n",
    "\n",
    "- Feature scaling - less necessary for tree-based models\n",
    "- High class cardinality - hopefully not an issue\n",
    "- Feature imbalance - this is a possible issue, but we can address this\n",
    "  - SMOTE is an option for increasing the minority class\n",
    "\n",
    "## Splitting the data, cross-validation\n",
    "we have to split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46cda8",
   "metadata": {
    "id": "72be4cf4"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE()\n",
    "# Resampling before splitting the data can lead to data leakage\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "X_test_res, y_test_res = smote.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0f542",
   "metadata": {
    "id": "6b56123a"
   },
   "source": [
    "## Train and evaluate a random forest (RF) model\n",
    "\n",
    "We will use the RF implementation from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b758f",
   "metadata": {
    "id": "6b56123a"
   },
   "outputs": [],
   "source": [
    "# What hyper-parameter should we use?\n",
    "best_params = {'bootstrap': False, \n",
    "               'max_depth': None, \n",
    "               'max_features': 'log2', \n",
    "               'min_samples_leaf': 1, \n",
    "               'min_samples_split': 5, \n",
    "               'n_estimators': 300} # WARNING: tuned on Floral molecules -- may not apply to others\n",
    "\n",
    "log_params({'rf_' + key:value for key,value in best_params.items()})\n",
    "\n",
    "model = sklearn_ensemble.RandomForestClassifier(**best_params)\n",
    "model_res = sklearn_ensemble.RandomForestClassifier(**best_params)\n",
    "\n",
    "# How do we fit and inference with the model?\n",
    "rf_y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "rf_y_pred_res = model_res.fit(X_train_res, y_train_res).predict(X_test_res)\n",
    "rf_y_pred_res2uns = model_res.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f1fb5",
   "metadata": {
    "id": "f18bca3d"
   },
   "source": [
    "And out of curiosity, let's also try an ensemble - even though for production-level models, this is likely overkill. A tiny performance boost often isn't worth the time and complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c538046",
   "metadata": {
    "id": "56d7f4dd"
   },
   "source": [
    "## Scoring / Evaluation ðŸ“\n",
    "\n",
    "How do we evaluate the model performance? What metrics are relevant here?\n",
    "\n",
    "This is binary classification - we care about precision, recall, F1, and AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a8a9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "19f90c57",
    "outputId": "addce402-1aed-4959-96de-9632e7cb2a35"
   },
   "outputs": [],
   "source": [
    "# What sort of visualization is needed here?\n",
    "print(\"----------------\")\n",
    "print(\"Random Forest\")\n",
    "print(\"----------------\")\n",
    "suptitle = 'Random Forest'\n",
    "gin.validate.evaluate_model(y_test, rf_y_pred)\n",
    "gin.validate.plot_confusion_matrix(y_test, rf_y_pred, suptitle=suptitle)\n",
    "save_fig(f'{desc}_confusion_matrix_rf')\n",
    "log_metrics(gin.validate.get_metrics(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba167e23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "1f576b60",
    "outputId": "245b2701-1c5f-4618-8969-6ec731bc10d1"
   },
   "outputs": [],
   "source": [
    "print(\"----------------\")\n",
    "print(\"Random Forest - Resampled\")\n",
    "print(\"----------------\")\n",
    "suptitle = 'Random Forest - Resampled'\n",
    "gin.validate.evaluate_model(y_test, rf_y_pred_res2uns)\n",
    "gin.validate.plot_confusion_matrix(y_test, rf_y_pred_res2uns, suptitle=suptitle)\n",
    "save_fig(f'{desc}_confusion_matrix_rf_resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d959c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4f07b95",
    "outputId": "e4411c03-a672-463b-f072-9152bb24142a"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression(max_iter=1000)\n",
    "clf2 = sklearn_ensemble.RandomForestClassifier(**best_params)\n",
    "clf3 = sklearn_ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# VotingClassifier with hard voting\n",
    "model_vote = sklearn_ensemble.VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gb', clf3)], voting='hard')\n",
    "model_vote_res = sklearn_ensemble.VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gb', clf3)], voting='hard')\n",
    "\n",
    "# Fit and predict\n",
    "print(\"Fitting vote model\")\n",
    "model_vote.fit(X_train, y_train)\n",
    "eclf_y_pred = model_vote.predict(X_test)\n",
    "\n",
    "print(\"Fitting the res vote model\")\n",
    "model_vote_res.fit(X_train_res, y_train_res)\n",
    "eclf_y_pred_res = model_vote_res.predict(X_test_res)\n",
    "eclf_y_pred_res2uns = model_vote_res.predict(X_test)\n",
    "\n",
    "print(\"Time taken: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36857c6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "793c8713",
    "outputId": "66382dad-b565-4fb2-8b58-d6ae96a957e2"
   },
   "outputs": [],
   "source": [
    "print(\"----------------\")\n",
    "print(\"Ensemble\")\n",
    "print(\"----------------\")\n",
    "suptitle = \"Ensemble\"\n",
    "gin.validate.evaluate_model(y_test, eclf_y_pred)\n",
    "gin.validate.plot_confusion_matrix(y_test, eclf_y_pred, suptitle=suptitle)\n",
    "save_fig(f'{desc}_confusion_matrix_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999679aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "c3c0307b",
    "outputId": "010dd927-72a9-4477-924e-1499e6556a8a"
   },
   "outputs": [],
   "source": [
    "print(\"----------------\")\n",
    "print(\"Ensemble - Resampled\")\n",
    "print(\"----------------\")\n",
    "suptitle = \"Ensemble - Resampled\"\n",
    "gin.validate.evaluate_model(y_test, eclf_y_pred_res2uns)\n",
    "gin.validate.plot_confusion_matrix(y_test, eclf_y_pred_res2uns, suptitle=suptitle)\n",
    "save_fig(f'{desc}_confusion_matrix_ensemble_resampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335ad4b",
   "metadata": {
    "id": "4c7cf486"
   },
   "source": [
    "By default random forest sets a default, but perhaps that's not ideal. We have a great deal of choice for type I type II error, and situationally these change.\n",
    "\n",
    "So let's examine how everything changes as a function of threshold.\n",
    "\n",
    "> Note: for hyperparameter tuning, usually we want a train, test, and validation set. But since it already works well above with SMOTE, I'm going to forgo a validation set for this exercise ðŸ˜ˆ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2da322",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fc517317",
    "outputId": "f41f7a59-f971-4668-9470-862402eb6521"
   },
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, 0.01)\n",
    "results_df_res = gin.validate.evaluate_thresholds(model_res, X_test,\n",
    "                                                  y_test, thresholds)\n",
    "results_df = gin.validate.evaluate_thresholds(model, X_test, y_test,\n",
    "                                              thresholds)\n",
    "gin.validate.plot_threshold_results(results_df_res, model_name='Random Forest', suptitle='Random Forest - Resampled')\n",
    "save_fig(f'{desc}_threshold_results_rf_resampled')\n",
    "gin.validate.plot_threshold_results(results_df, model_name='Random Forest', suptitle='Random Forest')\n",
    "save_fig(f'{desc}_threshold_results_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d8505",
   "metadata": {
    "id": "d1a0230f"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Class imbalance correction creates a modest improvement.\n",
    "\n",
    "The correct threshold depends on what we're optimizing for: do we want to balance precision recall for floral molecules or non-floral?\n",
    "\n",
    "Generally, we should pick a threshold somewhere in the goldilocks zone (shown in gray above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6433af9d",
   "metadata": {
    "id": "b043bdab"
   },
   "source": [
    "# Multi-layer Perceptron \n",
    "Let's traina simple neural network.\n",
    "\n",
    "Now that we have tried modeling with an RF, let's try modeling with a simple neural network: the [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron).\n",
    "\n",
    "This exercise aims to see whether we can train a PyTorch neural network from end to end, so a simple sanity check is adequate, and a thorough evaluation is **not** required.\n",
    "\n",
    "## Build the MLP module and model API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262fcb3a",
   "metadata": {
    "id": "7af0283b"
   },
   "source": [
    "## Setup a simple data loader and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b202f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "6d0890f44e814206bd30c60201f45332",
      "a0475cc35b8b407e8a942e3fbd35cfc4",
      "edc52d907cda4314b9ac9460a872695d",
      "1f4281bceda244acb2a23c4cea260031",
      "84eee56305d74f52ad64ec48c5069cc6",
      "09f05218359641219abbc8361ccbddb0",
      "990c50f9973746638302901163199cba",
      "87ea4a0a693248218bce9a33d9030e5c",
      "688738e111ea43cb9cc0204e2a507b5f",
      "cd518f62f2764893b3c59b5ac4f69956",
      "3f5e690936784b86909fd851156c96fc",
      "788cc0bc124d42aeb7edf793a1f89673",
      "c31cb31f9d5e4a80a911594fa205eeb4",
      "0c1522e6c36041dda0bf29797885828e",
      "66d15d87fd9940af84329d9aef29b163",
      "7302c3f754f145e5bb5769198f776b29",
      "c1385ef173004e369c46d1e547e92cf1",
      "7f287cf51cc24b60ac6aca67bd509490",
      "b1bfc77433c044cd879ec167309e8d3c",
      "9d21d4e393284d6aa0cc80d4b0f25bbf",
      "5dae1ccc76fb4370976e37a003a42b9b",
      "d7d18611bb8c4eda89b9e8925d302575"
     ]
    },
    "id": "71afc38b",
    "outputId": "dfcb4c9c-ea77-4064-a789-f98d40e8a569"
   },
   "outputs": [],
   "source": [
    "from gin.model import MLP\n",
    "model = MLP(input_dim=X_train.shape[1])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model_res = MLP(input_dim=X_train_res.shape[1])\n",
    "model_res.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d8586",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "7c731a83",
    "outputId": "8ddff76c-2251-4e0d-f0ac-53ad9c155847"
   },
   "outputs": [],
   "source": [
    "# Sanity check â€” how do we know the model has learned from the data?\n",
    "mlp_y_pred = model.predict(X_test)\n",
    "mlp_y_pred_res = model_res.predict(X_test)\n",
    "mlp_y_pred_res2uns = model_res.predict(X_test)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].hist([mlp_y_pred, y_test], bins=20, label=['MLP', 'True'], color=['gray', 'red'])\n",
    "axs[1].hist([mlp_y_pred_res2uns, y_test], bins=20, label=['MLP_res', 'True'], color=['black', 'red'])\n",
    "axs[0].set_title('MLP')\n",
    "axs[1].set_title('MLP - Resampled')\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e545eeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "48364b32",
    "outputId": "e7ed5066-abee-4991-e3f0-15f7f42d9216"
   },
   "outputs": [],
   "source": [
    "# As before, let's just explore the default threshold > 0.5\n",
    "print(\"----------------\")\n",
    "print(\"MLP\")\n",
    "print(\"----------------\")\n",
    "suptitle = 'MLP'\n",
    "gin.validate.evaluate_model(y_test, mlp_y_pred>0.5)\n",
    "gin.validate.plot_confusion_matrix(y_test, mlp_y_pred>0.5, suptitle=suptitle)\n",
    "save_fig(f'{desc}_confusion_matrix_mlp')\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"MLP - Resampled\")\n",
    "print(\"----------------\")\n",
    "suptitle = 'MLP - Resampled'\n",
    "gin.validate.evaluate_model(y_test, mlp_y_pred_res2uns > 0.5)\n",
    "gin.validate.plot_confusion_matrix(y_test, mlp_y_pred_res2uns>0.5, suptitle=suptitle)\n",
    "save_fig(f'{desc}_confusion_matrix_mlp_resampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8a381",
   "metadata": {
    "id": "57d225e2"
   },
   "source": [
    "Let's also try to examine the threshold for the MLP's final sigmoid output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43382b2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5fd0516a",
    "outputId": "4bdd2001-04c9-4dd6-809f-434ff53b4712"
   },
   "outputs": [],
   "source": [
    "results_df_mlp = gin.validate.evaluate_thresholds(model,\n",
    "                                                  X_test,\n",
    "                                                  y_test,\n",
    "                                                  thresholds,\n",
    "                                                  y_proba=mlp_y_pred)\n",
    "results_df_mlp_res = gin.validate.evaluate_thresholds(model_res,\n",
    "                                                      X_test,\n",
    "                                                      y_test,\n",
    "                                                      thresholds,\n",
    "                                                      y_proba=mlp_y_pred_res)\n",
    "gin.validate.plot_threshold_results(results_df_mlp, model_name='MLP', suptitle='MLP')\n",
    "save_fig(f'{desc}_threshold_results_mlp')\n",
    "gin.validate.plot_threshold_results(results_df_mlp_res, model_name='MLP - Resampled', suptitle='MLP - Resampled')\n",
    "save_fig(f'{desc}_threshold_results_mlp_resampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02041060",
   "metadata": {
    "id": "5b528b92"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "The `MLP` achieves a very similar performance to the simpler method above.\n",
    "\n",
    "Notably, the resampled model for the `MLP` does **not** perform any better, unlike the `RandomForest` above. In practice, we could try other methods of rebalancing and data augmentation techniques given sparse samples.\n",
    "\n",
    "# Graph Neural Network, Bonus - Naive (ðŸ‘¶) \n",
    "\n",
    "For fun, let's dovetail this section with a very naive message-passing GNN approach  ðŸ¤–\n",
    "\n",
    "*NOTES OF INTEREST*  ðŸ“\n",
    "- We are doing this without resampling/data-augmentation -- so we _may not approach_ performance above.\n",
    "- Instead, using a simpler class-imbalance reweighting function in the cross-entropy objective.\n",
    "- We may not have enough samples to utilize the capacity of a bigger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e284df3",
   "metadata": {
    "id": "bcbbe320-e334-4f9f-ab4e-bc9b72083a85"
   },
   "outputs": [],
   "source": [
    "# Convert the SMILES strings to graph data and split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from gin.extra.features import smiles_to_graph\n",
    "from gin.extra.gnn import train_gnn_model\n",
    "\n",
    "# Convert the SMILES strings to graph data\n",
    "data_list = []\n",
    "for smile_string, floral in zip(data_df.index, data_df['floral']):\n",
    "    data = smiles_to_graph(smile_string)\n",
    "    if data is not None:\n",
    "        data.y = torch.tensor([floral], dtype=torch.float)  # Assign target value\n",
    "        data_list.append(data)\n",
    "data_list = gin.extra.features.normalize_data_list(data_list) # Normalize features\n",
    "\n",
    "if len(data_list) == 0:\n",
    "    raise ValueError(\"No valid graph data could be generated from the provided SMILES strings.\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea73ed9",
   "metadata": {
    "id": "825370e7-e109-44fa-91bf-88479e6851b8"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ebaa1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "40110c9b8b74451d8e71aea7ab593d68",
      "1da1d2bf253643c3adc7c3f307ce6516",
      "0c038ad3946c4254a9849c0d41430801",
      "9bb459bbae5b48288af1603c60f3d4e2",
      "5a119996bed041f3b3edba02b2016340",
      "ee218f9cc4274adb9f84bae90aba41c7",
      "d35859f8ea354e52a342313677684c77",
      "d38a773fe6a1465dae99c7ab0504682a",
      "cc7d67f462a245c499cc32d0e080ceec",
      "81b52f2e4814455fb4f11692f7c00bd3",
      "fffcb0fffede45e4a266fdbae08f2e73"
     ]
    },
    "id": "ae92f0d1-1166-4574-b408-4afa6017f33b",
    "outputId": "47abbceb-7798-4158-ac1f-7019e27767b1"
   },
   "outputs": [],
   "source": [
    "# Train the GNN model on the training data with SMOTE applied\n",
    "model = train_gnn_model(train_data, num_epochs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b42b3",
   "metadata": {
    "id": "3dc9096a-f432-4311-a90a-4ba1440de8b2"
   },
   "source": [
    "And now, let's run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f827e94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "33fd81bc-84d1-4849-b737-d24675067ca4",
    "outputId": "fba829b2-280c-4005-abbb-0326f0170e39"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        preds = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        all_preds.extend(preds.numpy().flatten())\n",
    "        all_labels.extend(batch.y.numpy().flatten())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(all_preds, bins=20, alpha=0.75, label='Predictions')\n",
    "plt.hist(all_labels, bins=20, alpha=0.75, label='True Labels')\n",
    "plt.legend()\n",
    "plt.title('Distribution of Predictions and True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc2f8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "f7d2c730-1355-42af-bd73-0e2391148b73",
    "outputId": "68db1a35-4de8-450c-f31d-ca561d93dd07"
   },
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "gin.validate.evaluate_model(all_labels, all_preds > 0.5)\n",
    "gin.validate.plot_confusion_matrix(all_labels, all_preds > 0.5, suptitle='GNN Model')\n",
    "save_fig(f'{desc}_confusion_matrix_gnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262b51f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "id": "a9e26046-26f5-4c6d-889f-43b8f8615b28",
    "outputId": "52a299a7-e1fd-4319-cb29-cc77f5316920"
   },
   "outputs": [],
   "source": [
    "from gin.extra.validate import evaluate_thresholds_gnn\n",
    "thresholds = np.arange(0.0,1.0,0.01)\n",
    "results = evaluate_thresholds_gnn(model, test_data, thresholds)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc01686",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "e059722a-11e8-4210-9b03-3f9d232d2c5f",
    "outputId": "5bb94d78-67b2-45e8-d85e-4dca2b573fbb"
   },
   "outputs": [],
   "source": [
    "gin.validate.plot_threshold_results(results, model_name=\"GNN\")\n",
    "save_fig(f'{desc}_threshold_results_gnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31aeb7",
   "metadata": {
    "id": "5b528b92"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "The `MLP` achieves a very similar performance to the simpler method above.\n",
    "\n",
    "Notably, the resampled model for the `MLP` does **not** perform any better, unlike the `RandomForest` above. In practice, we could try other methods of rebalancing and data augmentation techniques given sparse samples.\n",
    "\n",
    "The GNN model, while an interesting exercise, does not perform as well as the simpler models. This is typical for neural networks with smaller datasets.\n",
    "\n",
    "<h4> Better yet -- pull a model from HuggingFace ðŸ¤—  that has been pre-trained on other molecules to leverage the knowledge seen in other data.</h4>\n",
    "\n",
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIN",
   "language": "python",
   "name": "in"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
